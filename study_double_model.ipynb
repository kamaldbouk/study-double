{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Study Double Model**\n",
        "*Mohammad Hijazi and Kamal Dbouk*"
      ],
      "metadata": {
        "id": "SBpBLi_uYMlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating a Synthetic Dataset for Training"
      ],
      "metadata": {
        "id": "G0WglJq4WrK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjdBK1yrWg8D",
        "outputId": "894ca595-d2ea-4de1-95a3-3134757cadc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 1000\n",
            "Number of interactions: 4997\n",
            "Positive ratings: 1164\n",
            "Negative ratings: 3833\n",
            "\n",
            "User profiles sample:\n",
            "  user_id  age_norm                   major       communication_style  \\\n",
            "0  user_0  0.424724             Mathematics  Interactive Conversation   \n",
            "1  user_1  0.633199               Economics      Occasional Check-ins   \n",
            "2  user_2  0.319804                 Theater               Quiet Focus   \n",
            "3  user_3  0.610540             Mathematics  Interactive Conversation   \n",
            "4  user_4  0.781751  Information Technology      Occasional Check-ins   \n",
            "\n",
            "              goal  extraversion  agreeableness  conscientiousness  \\\n",
            "0    Brainstorming      0.596850       0.445833           0.099975   \n",
            "1         Research      0.183405       0.304242           0.524756   \n",
            "2  Problem Solving      0.859940       0.680308           0.450499   \n",
            "3         Research      0.495177       0.034389           0.909320   \n",
            "4          Writing      0.894827       0.597900           0.921874   \n",
            "\n",
            "   neuroticism  openness  totalSessions  totalGoals  totalTickedGoals  \\\n",
            "0     0.459249  0.333709             40          28                 2   \n",
            "1     0.431945  0.291229             42          20                14   \n",
            "2     0.013265  0.942202             14          22                 8   \n",
            "3     0.258780  0.662522              2          10                 5   \n",
            "4     0.088493  0.195983             40          25                15   \n",
            "\n",
            "   preferredStudyLength  preferredBreakLength  todayStudyLength  \n",
            "0                    41                    25               257  \n",
            "1                    81                    19               445  \n",
            "2                   109                    25               385  \n",
            "3                    23                    26               476  \n",
            "4                   101                    19                52  \n",
            "\n",
            "Interactions sample:\n",
            "    user_id partner_id  rating\n",
            "0  user_725   user_363       0\n",
            "1  user_524   user_904       0\n",
            "2  user_603   user_619       0\n",
            "3  user_663   user_107       0\n",
            "4  user_955   user_175       0\n",
            "\n",
            "Data saved to CSV files: user_profiles.csv, train_interactions.csv, val_interactions.csv\n",
            "\n",
            "User to index mapping (first 5):\n",
            "user_725 -> 0\n",
            "user_363 -> 1\n",
            "user_524 -> 2\n",
            "user_904 -> 3\n",
            "user_603 -> 4\n",
            "\n",
            "Total users encoded: 1000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "num_users = 1000\n",
        "num_interactions = 5000\n",
        "\n",
        "# Generate user profiles\n",
        "user_ids = [f\"user_{i}\" for i in range(num_users)]\n",
        "user_profiles = {}\n",
        "\n",
        "majors = [\n",
        "    \"Accounting\", \"Biology\", \"Business Administration\", \"Chemistry\",\n",
        "    \"Computer Science\", \"Economics\", \"Engineering\", \"English\",\n",
        "    \"Environmental Science\", \"Finance\", \"History\", \"Information Technology\",\n",
        "    \"Law\", \"Liberal Arts\", \"Mathematics\", \"Mechanical Engineering\",\n",
        "    \"Nursing\", \"Philosophy\", \"Physics\", \"Political Science\",\n",
        "    \"Psychology\", \"Sociology\", \"Theater\", \"Social Work\"\n",
        "]\n",
        "\n",
        "communication_styles = [\"Quiet Focus\", \"Occasional Check-ins\", \"Interactive Conversation\"]\n",
        "goals = [\"Exam Prep\", \"Writing\", \"Problem Solving\", \"Research\", \"Brainstorming\", \"General\"]\n",
        "\n",
        "# Dictionaries to map categorical features to numeric values\n",
        "major_to_idx = {major: idx for idx, major in enumerate(majors)}\n",
        "communication_to_idx = {style: idx for idx, style in enumerate(communication_styles)}\n",
        "goal_to_idx = {goal: idx for idx, goal in enumerate(goals)}\n",
        "\n",
        "# Generate profiles\n",
        "for user_id in user_ids:\n",
        "    age_norm = np.random.uniform(0.2, 0.8)\n",
        "\n",
        "    # Categorical features\n",
        "    major = np.random.choice(majors)\n",
        "    communication_style = np.random.choice(communication_styles)\n",
        "    goal = np.random.choice(goals)\n",
        "\n",
        "    # Personality traits (between 0 and 1)\n",
        "    extraversion = np.random.uniform(0, 1)\n",
        "    agreeableness = np.random.uniform(0, 1)\n",
        "    conscientiousness = np.random.uniform(0, 1)\n",
        "    neuroticism = np.random.uniform(0, 1)\n",
        "    openness = np.random.uniform(0, 1)\n",
        "\n",
        "    totalSessions = np.random.randint(1, 50)\n",
        "    totalGoals = np.random.randint(5, 30)\n",
        "    totalTickedGoals = np.random.randint(0, totalGoals + 1)\n",
        "\n",
        "    preferredStudyLength = np.random.randint(20, 120)  # in minutes, between 20 and 120\n",
        "    preferredBreakLength = np.random.randint(5, 30)    # in minutes, between 5 and 30\n",
        "    todayStudyLength = np.random.randint(0, 480)       # in minutes, between 0 and 8 hours (480 minutes)\n",
        "\n",
        "    user_profiles[user_id] = {\n",
        "        'age_norm': age_norm,\n",
        "        'major': major,\n",
        "        'major_idx': major_to_idx[major],\n",
        "        'communication_style': communication_style,\n",
        "        'communication_style_idx': communication_to_idx[communication_style],\n",
        "        'goal': goal,\n",
        "        'goal_idx': goal_to_idx[goal],\n",
        "        'extraversion': extraversion,\n",
        "        'agreeableness': agreeableness,\n",
        "        'conscientiousness': conscientiousness,\n",
        "        'neuroticism': neuroticism,\n",
        "        'openness': openness,\n",
        "        'totalSessions': totalSessions,\n",
        "        'totalGoals': totalGoals,\n",
        "        'totalTickedGoals': totalTickedGoals,\n",
        "        'preferredStudyLength': preferredStudyLength,\n",
        "        'preferredBreakLength': preferredBreakLength,\n",
        "        'todayStudyLength': todayStudyLength\n",
        "    }\n",
        "\n",
        "profile_data = []\n",
        "for user_id in user_ids:\n",
        "    profile = user_profiles[user_id]\n",
        "    profile_data.append([\n",
        "        user_id,\n",
        "        profile['age_norm'],\n",
        "        profile['major'],\n",
        "        profile['communication_style'],\n",
        "        profile['goal'],\n",
        "        profile['extraversion'],\n",
        "        profile['agreeableness'],\n",
        "        profile['conscientiousness'],\n",
        "        profile['neuroticism'],\n",
        "        profile['openness'],\n",
        "        profile['totalSessions'],\n",
        "        profile['totalGoals'],\n",
        "        profile['totalTickedGoals'],\n",
        "        profile['preferredStudyLength'],\n",
        "        profile['preferredBreakLength'],\n",
        "        profile['todayStudyLength']\n",
        "    ])\n",
        "\n",
        "profile_df = pd.DataFrame(\n",
        "    profile_data,\n",
        "    columns=[\n",
        "        'user_id', 'age_norm', 'major', 'communication_style', 'goal',\n",
        "        'extraversion', 'agreeableness', 'conscientiousness', 'neuroticism', 'openness',\n",
        "        'totalSessions', 'totalGoals', 'totalTickedGoals',\n",
        "        'preferredStudyLength', 'preferredBreakLength', 'todayStudyLength'\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Generate interactions\n",
        "interactions = []\n",
        "for _ in range(num_interactions):\n",
        "    # Randomly select two users\n",
        "    user_id = np.random.choice(user_ids)\n",
        "    partner_id = np.random.choice(user_ids)\n",
        "\n",
        "    # Skip self-matches\n",
        "    if user_id == partner_id:\n",
        "        continue\n",
        "\n",
        "    # Get profiles\n",
        "    user_profile = user_profiles[user_id]\n",
        "    partner_profile = user_profiles[partner_id]\n",
        "\n",
        "    # Calculate compatibility based on features\n",
        "    age_diff = 1 - abs(user_profile['age_norm'] - partner_profile['age_norm'])\n",
        "\n",
        "    same_major = 1.0 if user_profile['major'] == partner_profile['major'] else 0.0\n",
        "    same_goal = 1.0 if user_profile['goal'] == partner_profile['goal'] else 0.0\n",
        "\n",
        "    comm_compat = 1.0 if user_profile['communication_style'] == partner_profile['communication_style'] else 0.0\n",
        "\n",
        "    # Personality compatibility\n",
        "    personality_compat = (user_profile['extraversion'] * partner_profile['agreeableness'] +\n",
        "                       partner_profile['extraversion'] * user_profile['agreeableness']) / 2\n",
        "\n",
        "    compatibility = (\n",
        "        0.2 * age_diff +\n",
        "        0.3 * same_major +\n",
        "        0.2 * same_goal +\n",
        "        0.1 * comm_compat +\n",
        "        0.2 * personality_compat\n",
        "    )\n",
        "\n",
        "    # Convert to binary rating with some noise\n",
        "    rating = 1 if compatibility > 0.4 else 0\n",
        "\n",
        "    # Add some noise to make it more realistic\n",
        "    if np.random.random() < 0.1:  # 10% noise\n",
        "        rating = 1 - rating\n",
        "\n",
        "    interactions.append((user_id, partner_id, rating))\n",
        "\n",
        "interactions_df = pd.DataFrame(interactions, columns=['user_id', 'partner_id', 'rating'])\n",
        "\n",
        "train_df, val_df = train_test_split(interactions_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Number of users: {num_users}\")\n",
        "print(f\"Number of interactions: {len(interactions_df)}\")\n",
        "print(f\"Positive ratings: {interactions_df['rating'].sum()}\")\n",
        "print(f\"Negative ratings: {len(interactions_df) - interactions_df['rating'].sum()}\")\n",
        "print(\"\\nUser profiles sample:\")\n",
        "print(profile_df.head())\n",
        "print(\"\\nInteractions sample:\")\n",
        "print(interactions_df.head())\n",
        "\n",
        "np.save('major_mapping.npy', major_to_idx)\n",
        "np.save('communication_mapping.npy', communication_to_idx)\n",
        "np.save('goal_mapping.npy', goal_to_idx)\n",
        "\n",
        "profile_df.to_csv('user_profiles.csv', index=False)\n",
        "train_df.to_csv('train_interactions.csv', index=False)\n",
        "val_df.to_csv('val_interactions.csv', index=False)\n",
        "print(\"\\nData saved to CSV files: user_profiles.csv, train_interactions.csv, val_interactions.csv\")\n",
        "\n",
        "unique_users = pd.unique(interactions_df[['user_id', 'partner_id']].values.ravel())\n",
        "user2idx = {uid: idx for idx, uid in enumerate(unique_users)}\n",
        "\n",
        "print(\"\\nUser to index mapping (first 5):\")\n",
        "for i, (uid, idx) in enumerate(list(user2idx.items())[:5]):\n",
        "    print(f\"{uid} -> {idx}\")\n",
        "print(f\"\\nTotal users encoded: {len(user2idx)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tier 1:"
      ],
      "metadata": {
        "id": "kodqU85IZskE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clustering"
      ],
      "metadata": {
        "id": "brnUHiwJYyG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def cluster_users(user_profiles_df, n_clusters=4):\n",
        "    print(\"\\nClustering users based on study preferences...\")\n",
        "\n",
        "    # Extract study preference features\n",
        "    study_features = user_profiles_df[['preferredStudyLength', 'preferredBreakLength', 'todayStudyLength']].values\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    study_features_scaled = scaler.fit_transform(study_features)\n",
        "\n",
        "    # Apply K-means clusteing\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    clusters = kmeans.fit_predict(study_features_scaled)\n",
        "    user_profiles_df['cluster'] = clusters\n",
        "\n",
        "    print(f\"Created {n_clusters} user clusters:\")\n",
        "    for cluster_id in range(n_clusters):\n",
        "        cluster_users = user_profiles_df[user_profiles_df['cluster'] == cluster_id]\n",
        "        print(f\"  Cluster {cluster_id}: {len(cluster_users)} users\")\n",
        "        print(f\"    Avg preferredStudyLength: {cluster_users['preferredStudyLength'].mean():.1f} minutes\")\n",
        "        print(f\"    Avg preferredBreakLength: {cluster_users['preferredBreakLength'].mean():.1f} minutes\")\n",
        "        print(f\"    Avg todayStudyLength: {cluster_users['todayStudyLength'].mean():.1f} minutes\")\n",
        "\n",
        "    return user_profiles_df\n",
        "\n",
        "user_profiles_df = cluster_users(profile_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIUciBpUYrL1",
        "outputId": "b0fd29d0-8b15-4ee1-ab77-b972de947666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Clustering users based on study preferences...\n",
            "Created 4 user clusters:\n",
            "  Cluster 0: 243 users\n",
            "    Avg preferredStudyLength: 98.0 minutes\n",
            "    Avg preferredBreakLength: 15.2 minutes\n",
            "    Avg todayStudyLength: 360.8 minutes\n",
            "  Cluster 1: 237 users\n",
            "    Avg preferredStudyLength: 41.4 minutes\n",
            "    Avg preferredBreakLength: 19.6 minutes\n",
            "    Avg todayStudyLength: 340.0 minutes\n",
            "  Cluster 2: 246 users\n",
            "    Avg preferredStudyLength: 82.2 minutes\n",
            "    Avg preferredBreakLength: 23.9 minutes\n",
            "    Avg todayStudyLength: 126.4 minutes\n",
            "  Cluster 3: 274 users\n",
            "    Avg preferredStudyLength: 62.6 minutes\n",
            "    Avg preferredBreakLength: 10.3 minutes\n",
            "    Avg todayStudyLength: 141.9 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tier 2:"
      ],
      "metadata": {
        "id": "BekXHEllZk-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Reciprocal Collaborative Filtering"
      ],
      "metadata": {
        "id": "s3b49MvdZaL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReciprocalDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, interactions_df, user_profiles_df, user2idx,\n",
        "                 major_mapping, communication_mapping, goal_mapping):\n",
        "        self.interactions = interactions_df\n",
        "        self.user_profiles = user_profiles_df.set_index('user_id')\n",
        "        self.user2idx = user2idx\n",
        "        self.major_mapping = major_mapping\n",
        "        self.communication_mapping = communication_mapping\n",
        "        self.goal_mapping = goal_mapping\n",
        "\n",
        "        self.numeric_features = ['age_norm', 'extraversion', 'agreeableness',\n",
        "                                'conscientiousness', 'neuroticism', 'openness']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.interactions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.interactions.iloc[idx]\n",
        "        user_id = row['user_id']\n",
        "        partner_id = row['partner_id']\n",
        "\n",
        "        u = self.user2idx[user_id]\n",
        "        v = self.user2idx[partner_id]\n",
        "\n",
        "        y = row['rating']\n",
        "\n",
        "        # Get numeric features\n",
        "        u_numeric = self.user_profiles.loc[user_id][self.numeric_features].values.astype(np.float32)\n",
        "        v_numeric = self.user_profiles.loc[partner_id][self.numeric_features].values.astype(np.float32)\n",
        "\n",
        "        # Get categorical features and convert to one-hot\n",
        "        u_major_idx = self.major_mapping[self.user_profiles.loc[user_id]['major']]\n",
        "        u_comm_idx = self.communication_mapping[self.user_profiles.loc[user_id]['communication_style']]\n",
        "        u_goal_idx = self.goal_mapping[self.user_profiles.loc[user_id]['goal']]\n",
        "\n",
        "        v_major_idx = self.major_mapping[self.user_profiles.loc[partner_id]['major']]\n",
        "        v_comm_idx = self.communication_mapping[self.user_profiles.loc[partner_id]['communication_style']]\n",
        "        v_goal_idx = self.goal_mapping[self.user_profiles.loc[partner_id]['goal']]\n",
        "\n",
        "        return (\n",
        "            torch.tensor(u),\n",
        "            torch.tensor(v),\n",
        "            torch.tensor(u_numeric),\n",
        "            torch.tensor(v_numeric),\n",
        "            torch.tensor(u_major_idx),\n",
        "            torch.tensor(u_comm_idx),\n",
        "            torch.tensor(u_goal_idx),\n",
        "            torch.tensor(v_major_idx),\n",
        "            torch.tensor(v_comm_idx),\n",
        "            torch.tensor(v_goal_idx),\n",
        "            torch.tensor(y, dtype=torch.float32)\n",
        "        )"
      ],
      "metadata": {
        "id": "BHY_Qa4GZZ7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NCRF Model"
      ],
      "metadata": {
        "id": "OuBg-m25dEqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NRCF(torch.nn.Module):\n",
        "    def __init__(self, num_users, num_majors, num_comm_styles, num_goals,\n",
        "                 numeric_dim=6, embed_dim=32, hidden_dims=(64, 32)):\n",
        "        super(NRCF, self).__init__()\n",
        "\n",
        "        # User embeddings\n",
        "        self.user_embedding = torch.nn.Embedding(num_users, embed_dim)\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.major_embedding = torch.nn.Embedding(num_majors, embed_dim)\n",
        "        self.comm_embedding = torch.nn.Embedding(num_comm_styles, embed_dim)\n",
        "        self.goal_embedding = torch.nn.Embedding(num_goals, embed_dim)\n",
        "\n",
        "        # Linear layers for numeric features\n",
        "        self.fc_numeric_user = torch.nn.Linear(numeric_dim, embed_dim)\n",
        "        self.fc_numeric_partner = torch.nn.Linear(numeric_dim, embed_dim)\n",
        "\n",
        "        # Prediction MLP\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(embed_dim * 8, hidden_dims[0]),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dims[1], 1),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, u_id, v_id, u_numeric, v_numeric,\n",
        "                u_major, u_comm, u_goal, v_major, v_comm, v_goal):\n",
        "        u_emb = self.user_embedding(u_id)\n",
        "        v_emb = self.user_embedding(v_id)\n",
        "\n",
        "        # Numeric feature projections\n",
        "        u_numeric_proj = self.fc_numeric_user(u_numeric)\n",
        "        v_numeric_proj = self.fc_numeric_partner(v_numeric)\n",
        "\n",
        "        # Categorical feature embeddings\n",
        "        u_major_emb = self.major_embedding(u_major)\n",
        "        u_comm_emb = self.comm_embedding(u_comm)\n",
        "        u_goal_emb = self.goal_embedding(u_goal)\n",
        "\n",
        "        v_major_emb = self.major_embedding(v_major)\n",
        "        v_comm_emb = self.comm_embedding(v_comm)\n",
        "        v_goal_emb = self.goal_embedding(v_goal)\n",
        "\n",
        "        # Combine user and partner feature embeddings\n",
        "        id_interaction = u_emb * v_emb\n",
        "\n",
        "        # For numeric features\n",
        "        numeric_interaction = u_numeric_proj * v_numeric_proj\n",
        "\n",
        "        # For categorical features\n",
        "        major_interaction = u_major_emb * v_major_emb\n",
        "        comm_interaction = u_comm_emb * v_comm_emb\n",
        "        goal_interaction = u_goal_emb * v_goal_emb\n",
        "\n",
        "        # Cross-feature interactions\n",
        "        u_id_v_numeric = u_emb * v_numeric_proj\n",
        "        v_id_u_numeric = v_emb * u_numeric_proj\n",
        "\n",
        "        # Combine all interactions\n",
        "        x = torch.cat([\n",
        "            id_interaction,\n",
        "            numeric_interaction,\n",
        "            major_interaction,\n",
        "            comm_interaction,\n",
        "            goal_interaction,\n",
        "            u_id_v_numeric,\n",
        "            v_id_u_numeric,\n",
        "            u_numeric_proj * v_emb\n",
        "        ], dim=1)\n",
        "\n",
        "        return self.mlp(x).squeeze()"
      ],
      "metadata": {
        "id": "zYAPm7oNaCZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, val_dataloader, epochs=5, lr=1e-3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    train_losses = []\n",
        "    val_accs = []\n",
        "    val_aucs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            u, v, u_numeric, v_numeric, u_major, u_comm, u_goal, v_major, v_comm, v_goal, y = batch\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(u, v, u_numeric, v_numeric, u_major, u_comm, u_goal, v_major, v_comm, v_goal)\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        train_losses.append(avg_loss)\n",
        "        print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        if val_dataloader:\n",
        "            model.eval()\n",
        "            val_preds, val_labels = [], []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in val_dataloader:\n",
        "                    u, v, u_numeric, v_numeric, u_major, u_comm, u_goal, v_major, v_comm, v_goal, y = batch\n",
        "                    preds = model(u, v, u_numeric, v_numeric, u_major, u_comm, u_goal, v_major, v_comm, v_goal)\n",
        "                    val_preds.append(preds)\n",
        "                    val_labels.append(y)\n",
        "\n",
        "            preds = torch.cat(val_preds).cpu().numpy()\n",
        "            labels = torch.cat(val_labels).cpu().numpy()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            acc = ((preds > 0.5).astype(float) == labels).mean()\n",
        "            val_accs.append(acc)\n",
        "\n",
        "            # Calculate AUC\n",
        "            from sklearn.metrics import roc_auc_score\n",
        "            auc_score = roc_auc_score(labels, preds)\n",
        "            val_aucs.append(auc_score)\n",
        "\n",
        "            print(f\"Validation Accuracy: {acc:.4f}, AUC: {auc_score:.4f}\")\n",
        "\n",
        "    return train_losses, val_accs, val_aucs"
      ],
      "metadata": {
        "id": "mM8pb_YlaNZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            u, v, u_numeric, v_numeric, u_major, u_comm, u_goal, v_major, v_comm, v_goal, y = batch\n",
        "            preds = model(u, v, u_numeric, v_numeric, u_major, u_comm, u_goal, v_major, v_comm, v_goal)\n",
        "            all_preds.append(preds)\n",
        "            all_labels.append(y)\n",
        "\n",
        "    all_preds = torch.cat(all_preds).cpu().numpy()\n",
        "    all_labels = torch.cat(all_labels).cpu().numpy()\n",
        "\n",
        "    # Binary accuracy\n",
        "    accuracy = ((all_preds > 0.5).astype(float) == all_labels).mean()\n",
        "\n",
        "    # AUC score\n",
        "    from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
        "    roc_auc = roc_auc_score(all_labels, all_preds)\n",
        "\n",
        "    # Precision-Recall AUC\n",
        "    precision, recall, _ = precision_recall_curve(all_labels, all_preds)\n",
        "    pr_auc = auc(recall, precision)\n",
        "\n",
        "    # Recommendation metrics\n",
        "    true_positives = sum((all_preds > 0.5) & (all_labels == 1))\n",
        "    false_positives = sum((all_preds > 0.5) & (all_labels == 0))\n",
        "    false_negatives = sum((all_preds <= 0.5) & (all_labels == 1))\n",
        "\n",
        "    precision_metric = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall_metric = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "    f1 = 2 * precision_metric * recall_metric / (precision_metric + recall_metric) if (precision_metric + recall_metric) > 0 else 0\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy,\n",
        "        'auc': roc_auc,\n",
        "        'pr_auc': pr_auc,\n",
        "        'precision': precision_metric,\n",
        "        'recall': recall_metric,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "    return results, all_preds, all_labels\n"
      ],
      "metadata": {
        "id": "h6NJQ3njaTDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load the data\n",
        "    train_interactions_df = pd.read_csv('train_interactions.csv')\n",
        "    val_interactions_df = pd.read_csv('val_interactions.csv')\n",
        "\n",
        "    # Load feature mappings\n",
        "    major_mapping = np.load('major_mapping.npy', allow_pickle=True).item()\n",
        "    communication_mapping = np.load('communication_mapping.npy', allow_pickle=True).item()\n",
        "    goal_mapping = np.load('goal_mapping.npy', allow_pickle=True).item()\n",
        "\n",
        "    # Encode users to indices\n",
        "    all_interactions = pd.concat([train_interactions_df, val_interactions_df])\n",
        "    unique_users = pd.unique(all_interactions[['user_id', 'partner_id']].values.ravel())\n",
        "    user2idx = {uid: idx for idx, uid in enumerate(unique_users)}\n",
        "    num_users = len(user2idx)\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = ReciprocalDataset(\n",
        "        train_interactions_df,\n",
        "        user_profiles_df,\n",
        "        user2idx,\n",
        "        major_mapping,\n",
        "        communication_mapping,\n",
        "        goal_mapping\n",
        "    )\n",
        "\n",
        "    val_dataset = ReciprocalDataset(\n",
        "        val_interactions_df,\n",
        "        user_profiles_df,\n",
        "        user2idx,\n",
        "        major_mapping,\n",
        "        communication_mapping,\n",
        "        goal_mapping\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Create and train the model\n",
        "    model = NRCF(\n",
        "        num_users=num_users,\n",
        "        num_majors=len(majors),\n",
        "        num_comm_styles=len(communication_styles),\n",
        "        num_goals=len(goals),\n",
        "        numeric_dim=6,\n",
        "        embed_dim=32,\n",
        "        hidden_dims=(64, 32)\n",
        "    )\n",
        "\n",
        "    print(f\"Training NRCF model with {num_users} users\")\n",
        "    print(f\"Number of majors: {len(majors)}\")\n",
        "    print(f\"Number of communication styles: {len(communication_styles)}\")\n",
        "    print(f\"Number of goals: {len(goals)}\")\n",
        "\n",
        "    train_losses, val_accs, val_aucs = train_model(\n",
        "        model,\n",
        "        train_dataloader,\n",
        "        val_dataloader,\n",
        "        epochs=15,\n",
        "        lr=1e-3\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"\\nFinal Model Evaluation:\")\n",
        "    results, preds, labels = evaluate_model(model, val_dataloader)\n",
        "    for metric, value in results.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Example of making predictions for a few user pairs\n",
        "    def predict_match(model, user1, user2, user_profiles_df, user2idx,\n",
        "                    major_mapping, communication_mapping, goal_mapping):\n",
        "        \"\"\"Make a prediction for a pair of users\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Get user indices\n",
        "        u_idx = torch.tensor([user2idx[user1]])\n",
        "        v_idx = torch.tensor([user2idx[user2]])\n",
        "\n",
        "        # Get user profiles\n",
        "        user1_profile = user_profiles_df[user_profiles_df['user_id'] == user1].iloc[0]\n",
        "        user2_profile = user_profiles_df[user_profiles_df['user_id'] == user2].iloc[0]\n",
        "\n",
        "        # Get numeric features\n",
        "        numeric_cols = ['age_norm', 'extraversion', 'agreeableness', 'conscientiousness', 'neuroticism', 'openness']\n",
        "        u_numeric = torch.tensor(user1_profile[numeric_cols].values.astype(np.float32)).unsqueeze(0)\n",
        "        v_numeric = torch.tensor(user2_profile[numeric_cols].values.astype(np.float32)).unsqueeze(0)\n",
        "\n",
        "        # Get categorical features\n",
        "        u_major = torch.tensor([major_mapping[user1_profile['major']]])\n",
        "        u_comm = torch.tensor([communication_mapping[user1_profile['communication_style']]])\n",
        "        u_goal = torch.tensor([goal_mapping[user1_profile['goal']]])\n",
        "\n",
        "        v_major = torch.tensor([major_mapping[user2_profile['major']]])\n",
        "        v_comm = torch.tensor([communication_mapping[user2_profile['communication_style']]])\n",
        "        v_goal = torch.tensor([goal_mapping[user2_profile['goal']]])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            score = model(\n",
        "                u_idx, v_idx,\n",
        "                u_numeric, v_numeric,\n",
        "                u_major, u_comm, u_goal,\n",
        "                v_major, v_comm, v_goal\n",
        "            ).item()\n",
        "\n",
        "        return score\n",
        "\n",
        "    print(\"\\nSample Predictions:\")\n",
        "    sample_pairs = [\n",
        "        (unique_users[0], unique_users[10]),\n",
        "        (unique_users[20], unique_users[30]),\n",
        "        (unique_users[40], unique_users[50])\n",
        "    ]\n",
        "\n",
        "    for user1, user2 in sample_pairs:\n",
        "        score = predict_match(\n",
        "            model, user1, user2, user_profiles_df, user2idx,\n",
        "            major_mapping, communication_mapping, goal_mapping\n",
        "        )\n",
        "\n",
        "        # Test reciprocal score\n",
        "        score_reverse = predict_match(\n",
        "            model, user2, user1, user_profiles_df, user2idx,\n",
        "            major_mapping, communication_mapping, goal_mapping\n",
        "        )\n",
        "\n",
        "        # Display profile detials\n",
        "        user1_profile = user_profiles_df[user_profiles_df['user_id'] == user1].iloc[0]\n",
        "        user2_profile = user_profiles_df[user_profiles_df['user_id'] == user2].iloc[0]\n",
        "\n",
        "        print(f\"\\nUser1: {user1}\")\n",
        "        print(f\"  Major: {user1_profile['major']}\")\n",
        "        print(f\"  Communication: {user1_profile['communication_style']}\")\n",
        "        print(f\"  Goal: {user1_profile['goal']}\")\n",
        "\n",
        "        print(f\"\\nUser2: {user2}\")\n",
        "        print(f\"  Major: {user2_profile['major']}\")\n",
        "        print(f\"  Communication: {user2_profile['communication_style']}\")\n",
        "        print(f\"  Goal: {user2_profile['goal']}\")\n",
        "\n",
        "        print(f\"\\n{user1} ↔ {user2}: {score:.4f} (match: {score > 0.5})\")\n",
        "        print(f\"{user2} ↔ {user1}: {score_reverse:.4f} (match: {score_reverse > 0.5})\")\n",
        "        print(f\"Difference in reciprocal scores: {abs(score - score_reverse):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XySaZQ0ZarWa",
        "outputId": "f20915a2-fe6a-429a-d256-cdd75e89c0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training NRCF model with 1000 users\n",
            "Number of majors: 24\n",
            "Number of communication styles: 3\n",
            "Number of goals: 6\n",
            "Epoch 1 - Loss: 0.5027\n",
            "Validation Accuracy: 0.8200, AUC: 0.7619\n",
            "Epoch 2 - Loss: 0.3881\n",
            "Validation Accuracy: 0.8260, AUC: 0.7597\n",
            "Epoch 3 - Loss: 0.3610\n",
            "Validation Accuracy: 0.8240, AUC: 0.7638\n",
            "Epoch 4 - Loss: 0.3303\n",
            "Validation Accuracy: 0.8190, AUC: 0.7656\n",
            "Epoch 5 - Loss: 0.3017\n",
            "Validation Accuracy: 0.8170, AUC: 0.7475\n",
            "Epoch 6 - Loss: 0.2705\n",
            "Validation Accuracy: 0.8260, AUC: 0.7560\n",
            "Epoch 7 - Loss: 0.2327\n",
            "Validation Accuracy: 0.8200, AUC: 0.7494\n",
            "Epoch 8 - Loss: 0.1890\n",
            "Validation Accuracy: 0.8140, AUC: 0.7480\n",
            "Epoch 9 - Loss: 0.1498\n",
            "Validation Accuracy: 0.8110, AUC: 0.7380\n",
            "Epoch 10 - Loss: 0.1119\n",
            "Validation Accuracy: 0.7920, AUC: 0.7296\n",
            "Epoch 11 - Loss: 0.0753\n",
            "Validation Accuracy: 0.8000, AUC: 0.7333\n",
            "Epoch 12 - Loss: 0.0476\n",
            "Validation Accuracy: 0.7980, AUC: 0.7259\n",
            "Epoch 13 - Loss: 0.0324\n",
            "Validation Accuracy: 0.7930, AUC: 0.7262\n",
            "Epoch 14 - Loss: 0.0231\n",
            "Validation Accuracy: 0.7950, AUC: 0.7319\n",
            "Epoch 15 - Loss: 0.0193\n",
            "Validation Accuracy: 0.7890, AUC: 0.7253\n",
            "\n",
            "Final Model Evaluation:\n",
            "accuracy: 0.7890\n",
            "auc: 0.7253\n",
            "pr_auc: 0.5621\n",
            "precision: 0.5782\n",
            "recall: 0.5000\n",
            "f1: 0.5363\n",
            "\n",
            "Sample Predictions:\n",
            "\n",
            "User1: user_166\n",
            "  Major: History\n",
            "  Communication: Quiet Focus\n",
            "  Goal: General\n",
            "\n",
            "User2: user_581\n",
            "  Major: Finance\n",
            "  Communication: Quiet Focus\n",
            "  Goal: Research\n",
            "\n",
            "user_166 ↔ user_581: 0.8612 (match: True)\n",
            "user_581 ↔ user_166: 0.9326 (match: True)\n",
            "Difference in reciprocal scores: 0.0714\n",
            "\n",
            "User1: user_271\n",
            "  Major: Sociology\n",
            "  Communication: Quiet Focus\n",
            "  Goal: Brainstorming\n",
            "\n",
            "User2: user_655\n",
            "  Major: English\n",
            "  Communication: Occasional Check-ins\n",
            "  Goal: Research\n",
            "\n",
            "user_271 ↔ user_655: 0.0000 (match: False)\n",
            "user_655 ↔ user_271: 0.0000 (match: False)\n",
            "Difference in reciprocal scores: 0.0000\n",
            "\n",
            "User1: user_95\n",
            "  Major: Law\n",
            "  Communication: Quiet Focus\n",
            "  Goal: Writing\n",
            "\n",
            "User2: user_540\n",
            "  Major: Physics\n",
            "  Communication: Interactive Conversation\n",
            "  Goal: General\n",
            "\n",
            "user_95 ↔ user_540: 0.0033 (match: False)\n",
            "user_540 ↔ user_95: 0.0677 (match: False)\n",
            "Difference in reciprocal scores: 0.0644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_partners(model, user_id, user_profiles_df, user2idx,\n",
        "                      major_mapping, communication_mapping, goal_mapping,\n",
        "                      top_k=5, use_clusters=True):\n",
        "        \"\"\"Recommend top-k partners for a given user from their cluster\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        user_cluster = user_profiles_df[user_profiles_df['user_id'] == user_id]['cluster'].values[0]\n",
        "\n",
        "        all_scores = []\n",
        "\n",
        "        potential_partners = user_profiles_df[user_profiles_df['cluster'] == user_cluster]['user_id'].values\n",
        "        print(f\"Matching {user_id} with {len(potential_partners)} users in cluster {user_cluster}\")\n",
        "\n",
        "\n",
        "        for other_id in potential_partners:\n",
        "            if other_id == user_id:\n",
        "                continue\n",
        "\n",
        "            score = predict_match(\n",
        "                model, user_id, other_id, user_profiles_df, user2idx,\n",
        "                major_mapping, communication_mapping, goal_mapping\n",
        "            )\n",
        "            all_scores.append((other_id, score))\n",
        "\n",
        "        # Sort by score in descending order\n",
        "        all_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Return top-k recommendations\n",
        "        return all_scores[:top_k]\n",
        "\n",
        "\n",
        "print(\"\\nSample Recommendations:\")\n",
        "for i in range(3):\n",
        "    sample_user = unique_users[i * 10]\n",
        "    user_profile = user_profiles_df[user_profiles_df['user_id'] == sample_user].iloc[0]\n",
        "\n",
        "    print(f\"\\nRecommendations for {sample_user}:\")\n",
        "    print(f\"  Major: {user_profile['major']}\")\n",
        "    print(f\"  Communication: {user_profile['communication_style']}\")\n",
        "    print(f\"  Goal: {user_profile['goal']}\")\n",
        "    print(f\"  Cluster: {user_profile['cluster']}\")\n",
        "    print(f\"  Study Preferences: {user_profile['preferredStudyLength']}min study, \" +\n",
        "          f\"{user_profile['preferredBreakLength']}min break, \" +\n",
        "          f\"{user_profile['todayStudyLength']}min today\")\n",
        "\n",
        "    # Get cluster-based recommendations\n",
        "    cluster_recommendations = recommend_partners(\n",
        "        model, sample_user, user_profiles_df, user2idx,\n",
        "        major_mapping, communication_mapping, goal_mapping,\n",
        "        use_clusters=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nTop 5 recommended partners from same cluster:\")\n",
        "    for j, (partner_id, score) in enumerate(cluster_recommendations):\n",
        "        partner_profile = user_profiles_df[user_profiles_df['user_id'] == partner_id].iloc[0]\n",
        "        print(f\"{j+1}. {partner_id} (Score: {score:.4f})\")\n",
        "        print(f\"   Major: {partner_profile['major']}\")\n",
        "        print(f\"   Communication: {partner_profile['communication_style']}\")\n",
        "        print(f\"   Goal: {partner_profile['goal']}\")\n",
        "        print(f\"   Study Preferences: {partner_profile['preferredStudyLength']}min study, \" +\n",
        "              f\"{partner_profile['preferredBreakLength']}min break, \" +\n",
        "              f\"{partner_profile['todayStudyLength']}min today\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGH_VW0EbJEb",
        "outputId": "41074022-1844-424d-f7ab-9b7d6b6ba0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Recommendations:\n",
            "\n",
            "Recommendations for user_166:\n",
            "  Major: History\n",
            "  Communication: Quiet Focus\n",
            "  Goal: General\n",
            "  Cluster: 2\n",
            "  Study Preferences: 45min study, 23min break, 68min today\n",
            "Matching user_166 with 246 users in cluster 2\n",
            "\n",
            "Top 5 recommended partners from same cluster:\n",
            "1. user_126 (Score: 1.0000)\n",
            "   Major: History\n",
            "   Communication: Interactive Conversation\n",
            "   Goal: General\n",
            "   Study Preferences: 112min study, 29min break, 11min today\n",
            "2. user_439 (Score: 1.0000)\n",
            "   Major: History\n",
            "   Communication: Quiet Focus\n",
            "   Goal: General\n",
            "   Study Preferences: 55min study, 29min break, 214min today\n",
            "3. user_647 (Score: 1.0000)\n",
            "   Major: Theater\n",
            "   Communication: Interactive Conversation\n",
            "   Goal: General\n",
            "   Study Preferences: 119min study, 21min break, 200min today\n",
            "4. user_537 (Score: 1.0000)\n",
            "   Major: Theater\n",
            "   Communication: Interactive Conversation\n",
            "   Goal: General\n",
            "   Study Preferences: 81min study, 20min break, 89min today\n",
            "5. user_476 (Score: 1.0000)\n",
            "   Major: Chemistry\n",
            "   Communication: Quiet Focus\n",
            "   Goal: General\n",
            "   Study Preferences: 116min study, 29min break, 72min today\n",
            "\n",
            "Recommendations for user_581:\n",
            "  Major: Finance\n",
            "  Communication: Quiet Focus\n",
            "  Goal: Research\n",
            "  Cluster: 1\n",
            "  Study Preferences: 50min study, 25min break, 415min today\n",
            "Matching user_581 with 237 users in cluster 1\n",
            "\n",
            "Top 5 recommended partners from same cluster:\n",
            "1. user_520 (Score: 1.0000)\n",
            "   Major: Finance\n",
            "   Communication: Interactive Conversation\n",
            "   Goal: Exam Prep\n",
            "   Study Preferences: 44min study, 25min break, 393min today\n",
            "2. user_637 (Score: 1.0000)\n",
            "   Major: Finance\n",
            "   Communication: Interactive Conversation\n",
            "   Goal: Writing\n",
            "   Study Preferences: 38min study, 29min break, 302min today\n",
            "3. user_782 (Score: 1.0000)\n",
            "   Major: Finance\n",
            "   Communication: Interactive Conversation\n",
            "   Goal: Research\n",
            "   Study Preferences: 44min study, 14min break, 258min today\n",
            "4. user_718 (Score: 1.0000)\n",
            "   Major: Theater\n",
            "   Communication: Quiet Focus\n",
            "   Goal: Research\n",
            "   Study Preferences: 66min study, 26min break, 300min today\n",
            "5. user_231 (Score: 1.0000)\n",
            "   Major: Theater\n",
            "   Communication: Quiet Focus\n",
            "   Goal: Research\n",
            "   Study Preferences: 76min study, 29min break, 393min today\n",
            "\n",
            "Recommendations for user_271:\n",
            "  Major: Sociology\n",
            "  Communication: Quiet Focus\n",
            "  Goal: Brainstorming\n",
            "  Cluster: 3\n",
            "  Study Preferences: 104min study, 6min break, 133min today\n",
            "Matching user_271 with 274 users in cluster 3\n",
            "\n",
            "Top 5 recommended partners from same cluster:\n",
            "1. user_868 (Score: 1.0000)\n",
            "   Major: Sociology\n",
            "   Communication: Quiet Focus\n",
            "   Goal: Brainstorming\n",
            "   Study Preferences: 46min study, 19min break, 122min today\n",
            "2. user_788 (Score: 1.0000)\n",
            "   Major: Philosophy\n",
            "   Communication: Quiet Focus\n",
            "   Goal: Brainstorming\n",
            "   Study Preferences: 55min study, 5min break, 158min today\n",
            "3. user_392 (Score: 1.0000)\n",
            "   Major: Engineering\n",
            "   Communication: Quiet Focus\n",
            "   Goal: Brainstorming\n",
            "   Study Preferences: 46min study, 5min break, 218min today\n",
            "4. user_736 (Score: 1.0000)\n",
            "   Major: Theater\n",
            "   Communication: Quiet Focus\n",
            "   Goal: Brainstorming\n",
            "   Study Preferences: 58min study, 6min break, 352min today\n",
            "5. user_571 (Score: 1.0000)\n",
            "   Major: Business Administration\n",
            "   Communication: Quiet Focus\n",
            "   Goal: Brainstorming\n",
            "   Study Preferences: 41min study, 13min break, 214min today\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tier 3:"
      ],
      "metadata": {
        "id": "pnBTK_16cy6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reranking"
      ],
      "metadata": {
        "id": "_oemcwVFcyyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rerank_recommendations(recommendations, user_id, user_profiles_df,\n",
        "                          diversity_weight=0.2, similarity_weight=0.5, productivity_weight=0.3,\n",
        "                          top_k=5):\n",
        "    import numpy as np\n",
        "\n",
        "    # Extract original recommendations and scores\n",
        "    partner_ids = [rec[0] for rec in recommendations]\n",
        "    original_scores = [rec[1] for rec in recommendations]\n",
        "\n",
        "    # Get profiles for all recommended partners\n",
        "    partner_profiles = user_profiles_df[user_profiles_df['user_id'].isin(partner_ids)]\n",
        "\n",
        "    # Calculate reranked scores\n",
        "    reranked_recommendations = []\n",
        "\n",
        "    # Weights for productivity metrics\n",
        "    goal_completion_weight = 0.7\n",
        "    sessions_weight = 0.3\n",
        "\n",
        "    for partner_id, original_score in recommendations:\n",
        "        partner_profile = partner_profiles[partner_profiles['user_id'] == partner_id].iloc[0]\n",
        "\n",
        "        # Calculate goal completion rate\n",
        "        goal_completion_rate = partner_profile['totalTickedGoals'] / partner_profile['totalGoals'] if partner_profile['totalGoals'] > 0 else 0\n",
        "\n",
        "        # Calculate session engagement (normalize total sessions)\n",
        "        max_sessions = 50\n",
        "        session_engagement = min(np.log1p(partner_profile['totalSessions']) / np.log1p(max_sessions), 1.0)\n",
        "\n",
        "        # Combine into a productivity score (the only factor for ranking now)\n",
        "        productivity_score = (\n",
        "            goal_completion_weight * goal_completion_rate +\n",
        "            sessions_weight * session_engagement\n",
        "        )\n",
        "\n",
        "        # Add to reranked recommendations\n",
        "        reranked_recommendations.append((partner_id, productivity_score, original_score, productivity_score))\n",
        "\n",
        "    # Sort by productivity score in descending order\n",
        "    reranked_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return top_k recommendations\n",
        "    return reranked_recommendations[:top_k]\n",
        "\n",
        "\n",
        "def display_reranked_recommendations(reranked_recommendations, user_profiles_df):\n",
        "    print(\"\\nReranked recommendations (optimized for productivity):\")\n",
        "    print(\"-\" * 110)\n",
        "    print(f\"{'Rank':<5} {'Partner ID':<10} {'Final':<10} {'Original':<10} {'Productivity':<12} \"\n",
        "          f\"{'Major':<20} {'Communication':<15} {'Goal':<8} {'Sessions':<8} {'Goals %':<8}\")\n",
        "    print(\"-\" * 110)\n",
        "\n",
        "    for i, (partner_id, new_score, original_score, productivity_score) in enumerate(reranked_recommendations, 1):\n",
        "        partner_profile = user_profiles_df[user_profiles_df['user_id'] == partner_id].iloc[0]\n",
        "        goal_completion = (partner_profile['totalTickedGoals'] / partner_profile['totalGoals'] * 100) if partner_profile['totalGoals'] > 0 else 0\n",
        "\n",
        "        print(f\"{i:<5} {partner_id:<10} {new_score:.4f}   {original_score:.4f}   {productivity_score:.4f}     \"\n",
        "              f\"{partner_profile['major'][:19]:<20} {partner_profile['communication_style']:<15} \"\n",
        "              f\"{partner_profile['goal']:<8} {partner_profile['totalSessions']:<8} {goal_completion:.1f}%\")\n",
        "\n",
        "\n",
        "reranked_recs = rerank_recommendations(cluster_recommendations, sample_user, user_profiles_df)\n",
        "display_reranked_recommendations(reranked_recs, user_profiles_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRXFGt3fc6lX",
        "outputId": "b30f0dae-5588-4bb4-d305-7e20265668b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Reranked recommendations (optimized for productivity):\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "Rank  Partner ID Final      Original   Productivity Major                Communication   Goal     Sessions Goals % \n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "1     user_736   0.8315   1.0000   0.8315     Theater              Quiet Focus     Brainstorming 22       84.6%\n",
            "2     user_868   0.7803   1.0000   0.7803     Sociology            Quiet Focus     Brainstorming 21       77.8%\n",
            "3     user_392   0.6421   1.0000   0.6421     Engineering          Quiet Focus     Brainstorming 45       50.0%\n",
            "4     user_571   0.6213   1.0000   0.6213     Business Administra  Quiet Focus     Brainstorming 5        69.2%\n",
            "5     user_788   0.1957   1.0000   0.1957     Philosophy           Quiet Focus     Brainstorming 12       0.0%\n"
          ]
        }
      ]
    }
  ]
}